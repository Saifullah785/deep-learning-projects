{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMDM5FvsLM3nHegys7u3y4v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saifullah785/deep-learning-projects/blob/main/Project_11_dog_breeds_detection_transfer_learning/Project_11_dog_breeds_detection_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load all Packages"
      ],
      "metadata": {
        "id": "gC5GojbFD5iu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xg3dq0VkS2zE"
      },
      "outputs": [],
      "source": [
        "# !pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# upload kaggle API token: then proceed\n",
        "# move api token\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "0d4Zrm6nECxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download dataset\n",
        "\n",
        "!kaggle dataset download -d 'mohamedchahed/dog-breeds'\n",
        "\n",
        "# unzip dataset\n",
        "!unzip dog-breeds.zip"
      ],
      "metadata": {
        "id": "P5ztsT7HEMU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense, BatchNormalization\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler"
      ],
      "metadata": {
        "id": "-AQxhpMuEjkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Augmentation"
      ],
      "metadata": {
        "id": "QFKZD6U0d4q9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating IMageDataGenerator instance to Augment,split and then pass our images to the model\n",
        "\n",
        "data_gen = ImageDataGenerator(rescale = 1./255,\n",
        "                              width_shift_range = 0.2,\n",
        "                              validation_split= 0.1,\n",
        "                              height_shift_range= 0.2,\n",
        "                              shear_range = 0.2,\n",
        "                              horizontal_flip = True,\n",
        "                              vertical_flip = True,\n",
        "                              zoom_range = 0.2)"
      ],
      "metadata": {
        "id": "wmM7YVG5d6z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Applying Data Augementation On both training and validation sets"
      ],
      "metadata": {
        "id": "mpLTKzXf-6_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating our test and validation data generator to flow images to network from images directory\n",
        "\n",
        "training_data = data_gen.flow_from_directory('/content/do-breeds',\n",
        "                                             target_size = (224,224),\n",
        "                                             class_mode = 'categorical',\n",
        "                                             subset = 'training')\n",
        "\n",
        "validation_data = data_gen.flow_from_directory('/content/do-breeds',\n",
        "                                               target_size = (224,224),\n",
        "                                               class_mode = 'categorical',\n",
        "                                               subset = 'validation')"
      ],
      "metadata": {
        "id": "rg_4CYqT_EUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading a Pretrained InceptionV3 Model by URL"
      ],
      "metadata": {
        "id": "W6_2nzO0oN6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading the pre-trained weights.\n",
        "# No top means it excludes the fully connected layer it uses for classification. we only need convolution layers.\n",
        "\n",
        "# In colab or kaggle notebook use the following\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O //content/sample_data/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n"
      ],
      "metadata": {
        "id": "nnJnth-DoOh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning Intialization and Configuration"
      ],
      "metadata": {
        "id": "B3r2udGvb3_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Set the weights file you download into a variable\n",
        "local_weights_file = '/content/sample_data/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "\n",
        "# Initialize the base model.\n",
        "# Set the input shape and remove the dense layers.\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (224, 224, 3),\n",
        "                                include_top = False,\n",
        "                                weights = None)\n",
        "\n",
        "# Load the pre-trained weights you downloded.\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Freeze the weights of th layers\n",
        "# As said before we don't want to re-train model's convolutional layers\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n"
      ],
      "metadata": {
        "id": "0o6XPXYscASb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose 'mixed_7' as the last layer of your base model\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ],
      "metadata": {
        "id": "VEFuUF5uc3MF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Architecture"
      ],
      "metadata": {
        "id": "RXaX3ngXz0et"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "\n",
        "# Add a fully connected layer with 1024 hidden units and Relu activation\n",
        "x = layer.Dense(1024, activatin='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)\n",
        "\n",
        "# Add a final sigmoid layer for classificatin\n",
        "x = layers.Dense (8, activation='softmax')(x)\n",
        "\n",
        "#Append the dense network to the base model\n",
        "model = Model(pre_trained_model.input, x)\n",
        "\n",
        "# print the model summary. See your dense network connected at the end\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "l3_y0_9w0PBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Compilation"
      ],
      "metadata": {
        "id": "SXO4bWW89Dqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the set of callback to be passed to the model during training\n",
        "# defining our scheduler\n",
        "def step_decay(epoch):\n",
        "  # initialize the base initial learning rate, drop factor, and\n",
        "  # epoch to drop every\n",
        "  initial_aplha = 0.01\n",
        "  fator = 0.5\n",
        "  drop_every_epoch = 5\n",
        "  # compute learning rate for the current epoch\n",
        "  alpha = initial_alpha * (factor ** np.floor((1 + epoch) / drop_every_epoch))\n",
        "  # return the learning rate\n",
        "  return float(alpha\n",
        "\n",
        "callbacks = [LearningRateScheduler(step_decay)]\n",
        "\n",
        "# initialize optimizer and model\n",
        "\n",
        "print('[INFO] compiling model...')\n",
        "\n",
        "opt = SGD(learning_rate =0.01, momentum=0.9,nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "3BePjFTA9H0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "bwKGSuD9-nKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Traint the model..\n",
        "history = model.fit(\n",
        "    training_data,\n",
        "    validation_data = validation_data,\n",
        "    epochs = 20,\n",
        "    callbacks = callbacks,\n",
        "    verbose = 1\n",
        ")"
      ],
      "metadata": {
        "id": "IlMfANpX-qnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot the Training Loss and Accuracy"
      ],
      "metadata": {
        "id": "XFBIkUiIm5Ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use('ggplot')\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, 20), history.history['loss'], label='train_loss')\n",
        "plt.plot(np.arange(0, 20), history.history['val_loss'], label='val_loss')\n",
        "plt.plot(np.arange(0, 20), history.history['accuracy'], label='train_acc')\n",
        "plt.plot(np.arange(0, 20), history.history['val_accuracy'], label='val_acc')\n",
        "plt.title('Training Loss and Accuracy on Dog-Breeds')\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('Loss/Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vYKim6rBm82j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}