{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMTG0YEpQA5jaoYXu9OXX/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saifullah785/deep-learning-projects/blob/main/Project_11_dog_breeds_detection_transfer_learning/Project_11_dog_breeds_detection_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load all Packages"
      ],
      "metadata": {
        "id": "gC5GojbFD5iu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xg3dq0VkS2zE"
      },
      "outputs": [],
      "source": [
        "# !pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# upload kaggle API token: then proceed\n",
        "# move api token\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "0d4Zrm6nECxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download dataset\n",
        "\n",
        "!kaggle dataset download -d 'mohamedchahed/dog-breeds'\n",
        "\n",
        "# unzip dataset\n",
        "!unzip dog-breeds.zip"
      ],
      "metadata": {
        "id": "P5ztsT7HEMU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense, BatchNormalization\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler"
      ],
      "metadata": {
        "id": "-AQxhpMuEjkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Augmentation"
      ],
      "metadata": {
        "id": "QFKZD6U0d4q9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating IMageDataGenerator instance to Augment,split and then pass our images to the model\n",
        "\n",
        "data_gen = ImageDataGenerator(rescale = 1./255,\n",
        "                              width_shift_range = 0.2,\n",
        "                              validation_split= 0.1,\n",
        "                              height_shift_range= 0.2,\n",
        "                              shear_range = 0.2,\n",
        "                              horizontal_flip = True,\n",
        "                              vertical_flip = True,\n",
        "                              zoom_range = 0.2)"
      ],
      "metadata": {
        "id": "wmM7YVG5d6z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Applying Data Augementation On both training and validation sets"
      ],
      "metadata": {
        "id": "mpLTKzXf-6_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating our test and validation data generator to flow images to network from images directory\n",
        "\n",
        "training_data = data_gen.flow_from_directory('/content/do-breeds',\n",
        "                                             target_size = (224,224),\n",
        "                                             class_mode = 'categorical',\n",
        "                                             subset = 'training')\n",
        "\n",
        "validation_data = data_gen.flow_from_directory('/content/do-breeds',\n",
        "                                               target_size = (224,224),\n",
        "                                               class_mode = 'categorical',\n",
        "                                               subset = 'validation')"
      ],
      "metadata": {
        "id": "rg_4CYqT_EUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading a Pretrained InceptionV3 Model by URL"
      ],
      "metadata": {
        "id": "W6_2nzO0oN6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading the pre-trained weights.\n",
        "# No top means it excludes the fully connected layer it uses for classification. we only need convolution layers.\n",
        "\n",
        "# In colab or kaggle notebook use the following\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O //content/sample_data/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n"
      ],
      "metadata": {
        "id": "nnJnth-DoOh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning Intialization and Configuration"
      ],
      "metadata": {
        "id": "B3r2udGvb3_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Set the weights file you download into a variable\n",
        "local_weights_file = '/content/sample_data/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "\n",
        "# Initialize the base model.\n",
        "# Set the input shape and remove the dense layers.\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (224, 224, 3),\n",
        "                                include_top = False,\n",
        "                                weights = None)\n",
        "\n",
        "# Load the pre-trained weights you downloded.\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Freeze the weights of th layers\n",
        "# As said before we don't want to re-train model's convolutional layers\n"
      ],
      "metadata": {
        "id": "0o6XPXYscASb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VEFuUF5uc3MF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}