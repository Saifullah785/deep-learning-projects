{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4wWctwxU2BPAKI++TFZVR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saifullah785/deep-learning-projects/blob/main/Project_12_Brain_Tumor_Detection_Using_Deep_Learning/Project_12_Brain_Tumor_Detection_Using_Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfT-wb5vfGAI",
        "outputId": "7fadc3cd-e2d4-4cdd-f3eb-bd8442c3d670"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports Libraries and Tools"
      ],
      "metadata": {
        "id": "EkBeNAdEhnDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image, ImageEnhance\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Flatten, Dropout, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from sklearn.utils import shuffle"
      ],
      "metadata": {
        "id": "QxcIUL74hm3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Datasets"
      ],
      "metadata": {
        "id": "Oebsrse-iq-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directories for training and testing data\n",
        "train_dir = '/content/drive/MyDrive/MRI Images/Training/'\n",
        "test_dir = '/content/drive/MyDrive/MRI Images/Testing/'\n",
        "\n",
        "# Load and shuffle the train data\n",
        "train_paths = []\n",
        "train_labels = []\n",
        "\n",
        "for label in os.listdir(train_dir):\n",
        "    for image in os.listdir(os.path.join(train_dir, label)):\n",
        "        train_paths.append(os.path.join(train_dir, label, image))\n",
        "        train_labels.append(label)\n",
        "\n",
        "train_paths, train_labels = shuffle(train_paths, train_labels)\n",
        "\n",
        "# Load and shuffle the test data\n",
        "test_paths = []\n",
        "test_labels = []\n",
        "\n",
        "for labels in os.listdir(test_dir):\n",
        "    for image in os.listdir(os.path.join(test_dir, label)):\n",
        "        test_paths.append(os.path.join(test_dir, label, image))\n",
        "        test_labels.append(label)\n",
        "\n",
        "test_paths, test_labels = shuffle(test_paths, test_labels)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BVdY9xyKitVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Visualization"
      ],
      "metadata": {
        "id": "qJsCW3VZcxWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Select random indices for 10 images\n",
        "random_indices = random.sample(rang(len(train_paths)), 10)\n",
        "\n",
        "# Create a figure to display images in 2 rows\n",
        "fig, axes = plt.subplots(2, 5, figsize=(15, 8))\n",
        "axes = axes.revel()\n",
        "\n",
        "for i, idx in enumerate(random_indices):\n",
        "  # load image\n",
        "  imge_path = train_paths[idx]\n",
        "  imge = Image.open(imge_path)\n",
        "  img = img.resize((224, 224))\n",
        "\n",
        "  # Display image\n",
        "  axes[i].imshow(img)\n",
        "  axes[i].axis('off')\n",
        "\n",
        "  # Display class label in the second row\n",
        "  axes[i].set_title(f'Label: {train_labels[idx]}', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FnD6MEFmc6Eq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Preprocessing (Helper Functions)"
      ],
      "metadata": {
        "id": "afIDyf9IF4Xk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# image Augmentation  function\n",
        "\n",
        "def augment_image(image):\n",
        "  image = Image.fromarray(np.uint8(image))\n",
        "  image = ImageEnhance.Brightness(image).enhance(random.uniform(0.8, 1.2))\n",
        "  image = ImageEnhance.Contrast(image).enhance(random.uniform(0.8, 1.2))\n",
        "  image = np.array(image) / 255.0\n",
        "  return image\n",
        "\n",
        "# Load images and apply augmention\n",
        "def Open_images(paths):\n",
        "  images = []\n",
        "  for path in paths:\n",
        "    image = load_img(path, target_size=(IMAGE_SIZE, IMAGE_SIZE))\n",
        "    image = augment_image(image)\n",
        "    images.append(image)\n",
        "  return np.array(images)\n",
        "\n",
        "# Encoding labels (convert label names to integers)\n",
        "def encode_labels(labels):\n",
        "  unique_labels = os.listdir(train_dir)\n",
        "  encoded = [unique_labels.index(label) for label in labels]\n",
        "  return np.array(encoded)\n",
        "\n",
        "# Data generator for batching\n",
        "def data_generator(paths, Labels, batch_size=12, epochs=1):\n",
        "  for _ in range(epochs):\n",
        "    for i in range(0, len(paths), batch_size):\n",
        "      batch_paths = paths[i:i + batch_size]\n",
        "      batch_images = open_images(batch_paths)\n",
        "      batch_labels = labels[i:i+batch_size]\n",
        "      batch_labels = encode_label(batch_labels)  # Encode labels\n",
        "      yield batch_images, batch_labels"
      ],
      "metadata": {
        "id": "4rJkf_hyF-tb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}