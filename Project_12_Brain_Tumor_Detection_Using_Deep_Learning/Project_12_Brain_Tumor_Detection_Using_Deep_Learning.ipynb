{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdpbmfIgJ+sm9K4tqoUlFX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saifullah785/deep-learning-projects/blob/main/Project_12_Brain_Tumor_Detection_Using_Deep_Learning/Project_12_Brain_Tumor_Detection_Using_Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfT-wb5vfGAI",
        "outputId": "7fadc3cd-e2d4-4cdd-f3eb-bd8442c3d670"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports Libraries and Tools"
      ],
      "metadata": {
        "id": "EkBeNAdEhnDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image, ImageEnhance\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Flatten, Dropout, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from sklearn.utils import shuffle"
      ],
      "metadata": {
        "id": "QxcIUL74hm3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Datasets"
      ],
      "metadata": {
        "id": "Oebsrse-iq-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directories for training and testing data\n",
        "train_dir = '/content/drive/MyDrive/MRI Images/Training/'\n",
        "test_dir = '/content/drive/MyDrive/MRI Images/Testing/'\n",
        "\n",
        "# Load and shuffle the train data\n",
        "train_paths = []\n",
        "train_labels = []\n",
        "\n",
        "for label in os.listdir(train_dir):\n",
        "    for image in os.listdir(os.path.join(train_dir, label)):\n",
        "        train_paths.append(os.path.join(train_dir, label, image))\n",
        "        train_labels.append(label)\n",
        "\n",
        "train_paths, train_labels = shuffle(train_paths, train_labels)\n",
        "\n",
        "# Load and shuffle the test data\n",
        "test_paths = []\n",
        "test_labels = []\n",
        "\n",
        "for labels in os.listdir(test_dir):\n",
        "    for image in os.listdir(os.path.join(test_dir, label)):\n",
        "        test_paths.append(os.path.join(test_dir, label, image))\n",
        "        test_labels.append(label)\n",
        "\n",
        "test_paths, test_labels = shuffle(test_paths, test_labels)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BVdY9xyKitVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Visualization"
      ],
      "metadata": {
        "id": "qJsCW3VZcxWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Select random indices for 10 images\n",
        "random_indices = random.sample(rang(len(train_paths)), 10)\n",
        "\n",
        "# Create a figure to display images in 2 rows\n",
        "fig, axes = plt.subplots(2, 5, figsize=(15, 8))\n",
        "axes = axes.revel()\n",
        "\n",
        "for i, idx in enumerate(random_indices):\n",
        "  # load image\n",
        "  imge_path = train_paths[idx]\n",
        "  imge = Image.open(imge_path)\n",
        "  img = img.resize((224, 224))\n",
        "\n",
        "  # Display image\n",
        "  axes[i].imshow(img)\n",
        "  axes[i].axis('off')\n",
        "\n",
        "  # Display class label in the second row\n",
        "  axes[i].set_title(f'Label: {train_labels[idx]}', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FnD6MEFmc6Eq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Preprocessing (Helper Functions)"
      ],
      "metadata": {
        "id": "afIDyf9IF4Xk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# image Augmentation  function\n",
        "\n",
        "def augment_image(image):\n",
        "  image = Image.fromarray(np.uint8(image))\n",
        "  image = ImageEnhance.Brightness(image).enhance(random.uniform(0.8, 1.2))\n",
        "  image = ImageEnhance.Contrast(image).enhance(random.uniform(0.8, 1.2))\n",
        "  image = np.array(image) / 255.0\n",
        "  return image\n",
        "\n",
        "# Load images and apply augmention\n",
        "def Open_images(paths):\n",
        "  images = []\n",
        "  for path in paths:\n",
        "    image = load_img(path, target_size=(IMAGE_SIZE, IMAGE_SIZE))\n",
        "    image = augment_image(image)\n",
        "    images.append(image)\n",
        "  return np.array(images)\n",
        "\n",
        "# Encoding labels (convert label names to integers)\n",
        "def encode_labels(labels):\n",
        "  unique_labels = os.listdir(train_dir)\n",
        "  encoded = [unique_labels.index(label) for label in labels]\n",
        "  return np.array(encoded)\n",
        "\n",
        "# Data generator for batching\n",
        "def data_generator(paths, Labels, batch_size=12, epochs=1):\n",
        "  for _ in range(epochs):\n",
        "    for i in range(0, len(paths), batch_size):\n",
        "      batch_paths = paths[i:i + batch_size]\n",
        "      batch_images = open_images(batch_paths)\n",
        "      batch_labels = labels[i:i+batch_size]\n",
        "      batch_labels = encode_label(batch_labels)  # Encode labels\n",
        "      yield batch_images, batch_labels"
      ],
      "metadata": {
        "id": "4rJkf_hyF-tb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model: WE ARE USING VGG16 FOR TRANSFER LEARNING."
      ],
      "metadata": {
        "id": "S3wQWor3GRpb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model architecture\n",
        "IMAGE_SIZE = 128\n",
        "base_model = VGG16(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), include_top=False, weights='imagenet')\n",
        "\n",
        "# Freeze all layers of the VGG16 base model\n",
        "for layer in base_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "# Set the last few layers of the VGG16 base model to be trainable\n",
        "base_model.layers[-2].trainable = True\n",
        "base_model.layers[-3].trainable = True\n",
        "base_model.layers[-4].trainable = True\n",
        "\n",
        "# Build the final model\n",
        "model = Sequential()\n",
        "model.add(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "model.add(base_model)\n",
        "model.add(Flatten())\n",
        "model.add(dropout(0.3))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(len(os.listdir(train_dir)), activation='softmax'))\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['spare_categorical_accuracy'])\n",
        "\n",
        "\n",
        "# Parameters\n",
        "batch_size =12\n",
        "steps = int(len(train_paths) / batch_size)\n",
        "epochs =5\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(datagen(train_paths, train_labels, batch_size=batch_size, epochs=epochs),\n",
        "                    epochs=epochs, steps_per_epoch=steps)"
      ],
      "metadata": {
        "id": "kpViqiV6Gw3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and Val Plots"
      ],
      "metadata": {
        "id": "MZaIn3m2HDgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,4))\n",
        "plt.grid(True)\n",
        "plt.plot(history.history['spare_category_accuracy'], '.g-', linewidth=2)\n",
        "plt.plot(history.history['loss'],'r-', linewidth=2)\n",
        "plt.title('Model Training History')\n",
        "plt.xlabel('epoch')\n",
        "plt.xticks([x for x in range(epochs)])\n",
        "plt.legend(['Accuracy', 'Loss'], loc='upper left',bbox_to_anchor=(1, 1))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ESVJEU9QdJyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Classification Report"
      ],
      "metadata": {
        "id": "DNLHXKirum78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "\n",
        "# 1. Prediction on test data\n",
        "test_images = open_images(test_paths)  # Load and augment test images\n",
        "test_labels_encoded = encode_label(test_labels)  # Encode the test labels\n",
        "\n",
        "# Predict using the trained model\n",
        "test_predictions = model.predict(test_images)\n",
        "\n",
        "# 2. Classification Report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(test_labels_encoded, np.argmax(test_predictions, axis=1)))"
      ],
      "metadata": {
        "id": "np0hiTCHuskD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Confusion Plot"
      ],
      "metadata": {
        "id": "3Rxc7SbM69dx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.confusion Matrix\n",
        "conf_matrix = confusion_matrix(test_labels_encoded, np.argmax(test_predictions, axis=1))\n",
        "print('Confusion Matrix:')\n",
        "print(conf_matrix)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d',cmap='Blues',xticklabels=os.listdir(train_dir), yticklabels=os.listdir(train_dir))\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "opBgyoz27BA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ROC Curve Plot"
      ],
      "metadata": {
        "id": "6-Q7VfLlt9jD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "4.ROC Curve and AUC\n",
        "# Binarize the test labels and predictions for multi-class ROC\n",
        "test_labels_bin = label_binarize(test_labels_encoded, classes=np.range(len(os.listdir(train_dir))))\n",
        "test_predictions_bin = test_predictions # The predicted probabilities for each class\n",
        "\n",
        "# Compute ROC curve and ROC AUC for each class\n",
        "fpr, tpr, roc_auc = {}, {}, {}\n",
        "for i in range(len(os.listdir(train_dir))):\n",
        "  fpr[i], tpr[i], _ = roc_curve(test_labels_bin[:, i], test_predictions_bin[:,i])\n",
        "\n",
        "  # Plot ROC curve\n",
        "  plt.figure(figsize=(10, 8))\n",
        "  for i in range(len(os.listdir(train_dir))):\n",
        "    plt.plot(fpr[i], tpr[i], label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n",
        "\n",
        "plt.plot([0,1], [0,1], linestyle='--', color='gray')\n",
        "plt.title('ROC Curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "upMi_E6cuBbJ"
      },
      "execution_count": 2,
      "outputs": []
    }
  ]
}